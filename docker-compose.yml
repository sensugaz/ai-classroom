services:
  # Pipeline runs separately on the GPU machine.
  # Use docker-compose --profile gpu up to include it,
  # or set PIPELINE_WS_URL to point to the external GPU server.
  pipeline:
    profiles: ["gpu"]
    build: ./services/pipeline
    ports:
      - "9000:9000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - model-cache:/root/.cache
      - ./services/pipeline/voice_presets:/app/voice_presets
    environment:
      - DEVICE=cuda
      - PORT=9000
    restart: unless-stopped

  api:
    build: ./services/api
    ports:
      - "8080:8080"
    environment:
      - PIPELINE_WS_URL=${PIPELINE_WS_URL:-ws://pipeline:9000/ws}
      - MONGO_URI=mongodb://mongodb:27017/classroom
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
    depends_on:
      - mongodb
    restart: unless-stopped

  web:
    build: ./web
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8080
      - NEXT_PUBLIC_WS_URL=ws://localhost:8080
    depends_on:
      - api
    restart: unless-stopped

  mongodb:
    image: mongo:7
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db
    restart: unless-stopped

volumes:
  model-cache:
  mongo-data:
